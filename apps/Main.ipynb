{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f1a00ec-9194-49f1-a34f-29f5a202d69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import math\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.subplots as sub\n",
    "import dash\n",
    "from dash import dcc, html, Output, Input, State\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_fscore_support, confusion_matrix, top_k_accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "#from optuna.integration import PyTorchIgnitePruningHandler\n",
    "\n",
    "from functools import partial\n",
    "import random\n",
    "import os\n",
    "import itertools\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, Subset\n",
    "from torchvision.models import vgg16_bn, resnet50, resnet18, efficientnet_b0, densenet121, ResNet50_Weights, ResNet18_Weights, VGG16_BN_Weights, DenseNet121_Weights, EfficientNet_B0_Weights\n",
    "from torchvision.utils import make_grid, draw_bounding_boxes, draw_segmentation_masks, draw_keypoints\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, v2, ToPILImage\n",
    "from torchvision.io import decode_image\n",
    "\n",
    "# from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "# from ignite.metrics import Accuracy, Loss, RunningAverage, ConfusionMatrix\n",
    "# from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from pathlib import Path\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.amp import GradScaler, autocast\n",
    "\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor, AutoModelForImageClassification, AutoImageProcessor, Trainer, TrainingArguments\n",
    "from huggingface_hub import snapshot_download, hf_hub_download\n",
    "import socket\n",
    "import json\n",
    "import sys\n",
    "import io\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0c89f3c-dbf0-40e5-ad9f-a2ef87e5a1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for python\n",
    "# sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'src')))\n",
    "# import data_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4740dd78-3744-4a31-acaf-80835b2844dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for notebook\n",
    "# sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', 'src')))\n",
    "# import helper_module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8f01f17-0c9d-4acf-97f3-e03b59c784d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\chihp\\\\UMich\\\\SIADS\\\\GitHub\\\\CV_aircraft_classifier_capstone_project\\\\apps'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56c7dea3-6985-41ad-86ba-1039a2ceaf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', 'src')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55f4cfe9-e981-486f-9b83-cc19685baffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import FGVCAircraftDataset, get_datasets, get_loaders, get_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dba5093-2f1b-4e36-8be5-d8979e5302d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aircraft_utils, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faa624e3-b7cf-420b-bd19-6e52ec3e67a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = get_raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14a76dde-c854-4037-a4f0-ead1bf9bd1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40ec7713-2ad8-4a56-bef2-ef60277adf3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:53598/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1d36ec17b60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize dash app.\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "LEVELS = ['manufacturer', 'family', 'variant']\n",
    "loaded_datasets = {}\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H2(\"FGVC Aircraft Dashboard\"), # dashboard title\n",
    "    dcc.RadioItems(\n",
    "        id='mode-selector',\n",
    "        options=[\n",
    "            {'label': 'Dataset Viewer', 'value': 'viewer'},\n",
    "            {'label': 'Pre-trained Model', 'value': 'pretrain'},\n",
    "            {'label': 'Run Training', 'value': 'train'},\n",
    "            \n",
    "        ],\n",
    "        value='viewer',\n",
    "        inline=True\n",
    "    ),\n",
    "    html.Div(id='common-controls', children=[\n",
    "        html.Label(\"Select Level:\"),\n",
    "        dcc.Dropdown(id='level-dropdown', options=[{'label': lvl.title(), 'value': lvl} for lvl in LEVELS])\n",
    "    ]),\n",
    "    html.Div(id='train-controls', style={'display': 'none'}, children=[\n",
    "        html.Label(\"Image Size:\"),\n",
    "        dcc.Input(id='img-size', type='number', value=224),\n",
    "        html.Label(\"Batch Size:\"),\n",
    "        dcc.Input(id='batch-size', type='number', value=16),\n",
    "        html.Label(\"Select Training Level:\"),\n",
    "        dcc.Dropdown(id='train-level-dropdown', options=[{'label': lvl.title(), 'value': lvl} for lvl in LEVELS], value='manufacturer'),\n",
    "        html.Label(\"Patience:\"),\n",
    "        dcc.Input(id='patience', type='number', value=2),\n",
    "        html.Label(\"Number of Epochs:\"),\n",
    "        dcc.Input(id='num-epochs', type='number', value=5),\n",
    "        html.Button('Start Training', id='train-button', n_clicks=0),\n",
    "        html.Div(id='train-status', style={'marginTop': '10px', 'color': 'blue'})\n",
    "    ]),\n",
    "    html.Div(id='predict-controls', children=[\n",
    "        html.Label(\"Number of Samples to Predict:\"),\n",
    "        dcc.Input(id='num-samples', type='number', min=1, max=50, value=10),\n",
    "        # html.Br(),\n",
    "        html.Label(\"Select Prediction Level:\"),\n",
    "        dcc.Dropdown(id='predict-level-dropdown', options=[{'label': lvl.title(), 'value': lvl} for lvl in LEVELS], value='manufacturer'),\n",
    "        html.Button('Run Prediction', id='predict-button', n_clicks=0),\n",
    "        #html.Div(id='prediction-output')\n",
    "        \n",
    "        dcc.Loading(\n",
    "            id='loading-predict',\n",
    "            type='circle',\n",
    "            children=html.Div(id='prediction-output')\n",
    "        )\n",
    "\n",
    "    ]),\n",
    "    html.Div(id='viewer-controls', style={'display': 'none'}, children=[\n",
    "        html.P(f\"Press Load Dataset button below or insert directory where you saved torchvision.datasets.FGVCAircraft() to.\"),\n",
    "        dcc.Input(id='path-input', type='text', placeholder='Enter dataset root path', style={'width': '60%'}, value=str(ROOT)),\n",
    "        html.Button('Load Dataset', id='load-button', n_clicks=0),\n",
    "        html.Div(id='load-status', style={'marginTop': '10px', 'color': 'green'}),\n",
    "        html.Br(),\n",
    "        html.Label(\"Select Level:\"),\n",
    "        dcc.Dropdown(id='lvl-dropdown', options=[{'label': lvl.title(), 'value': lvl} for lvl in LEVELS], value='manufacturer'),\n",
    "        html.Label(\"Select Class:\"),\n",
    "        dcc.Dropdown(id='class-dropdown'),\n",
    "        html.Div(id='image-output', style={'display': 'flex', 'flexWrap': 'wrap'})\n",
    "    ]),\n",
    "    #dcc.Store(id='model-meta-store')\n",
    "    dcc.Store(id='model-meta-store', data={})\n",
    "])\n",
    "@app.callback(\n",
    "    Output('train-controls', 'style'),\n",
    "    Output('predict-controls', 'style'),\n",
    "    Output('viewer-controls', 'style'),\n",
    "    Input('mode-selector', 'value')\n",
    ")\n",
    "def toggle_controls(mode):    \n",
    "    styles = {\n",
    "        'train': {'train': 'block', 'predict': 'block', 'viewer': 'none'},\n",
    "        'pretrain': {'train': 'none', 'predict': 'block', 'viewer': 'none'},\n",
    "        'viewer': {'train': 'none', 'predict': 'none', 'viewer': 'block'}\n",
    "    }\n",
    "    selected = styles.get(mode, {'train': 'none', 'predict': 'none', 'viewer': 'none'})\n",
    "\n",
    "    return (\n",
    "        {'display': 'block'} if mode == 'train' else {'display': 'none'},\n",
    "        {'display': 'block'} if mode in ['train', 'pretrain'] else {'display': 'none'},\n",
    "        {'display': 'block'} if mode == 'viewer' else {'display': 'none'}\n",
    "    )\n",
    "@app.callback(\n",
    "    [Output('train-status', 'children'),\n",
    "     Output('model-meta-store', 'data')],\n",
    "    Input('train-button', 'n_clicks'),\n",
    "    State('img-size', 'value'),\n",
    "    State('batch-size', 'value'),\n",
    "    State('train-level-dropdown', 'value'),\n",
    "    State('patience', 'value'),\n",
    "    State('num-epochs', 'value')\n",
    ")\n",
    "def run_training(n_clicks, img_size, batch_size, annot, patience, num_epochs):\n",
    "    if n_clicks > 0:\n",
    "        train_loader, val_loader, test_loader, num_classes, class_names = get_loaders(img_size=img_size, batch_size=batch_size, annot=annot)\n",
    "        model = models.CAPResNet(num_classes, drop=0.3563).to(device)\n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=0.046858)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=5.1872e-05, weight_decay=0.002925)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "        scaler = GradScaler('cuda')\n",
    "        best_val_loss = float('inf')\n",
    "        epochs_without_improvement = 0\n",
    "        model_path = os.path.join(os.pardir, \"models\", \"best_model_dash.pth\")\n",
    "        for epoch in range(num_epochs):\n",
    "            train_loss, train_acc, _, _ = aircraft_utils.train_one_epoch(model, train_loader, criterion, optimizer, 'cuda', scaler)\n",
    "            val_loss, val_acc, _, _, _, _ = aircraft_utils.evaluate(model, val_loader, criterion, 'cuda')\n",
    "            scheduler.step(val_loss)\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                epochs_without_improvement = 0\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "            else:\n",
    "                epochs_without_improvement += 1\n",
    "            if epochs_without_improvement >= patience:\n",
    "                break\n",
    "        return (\n",
    "            f\"Training for {num_epochs} epochs completed. Best model with {num_classes} classes at {annot} level saved as best_model_dash.pth with val loss {best_val_loss:.4f}\",\n",
    "            {'num_classes': num_classes, 'class_names': class_names}\n",
    "        )\n",
    "    return \"\", {}\n",
    "@app.callback(\n",
    "    Output('prediction-output', 'children'),\n",
    "    Input('predict-button', 'n_clicks'),\n",
    "    State('mode-selector', 'value'),\n",
    "    State('predict-level-dropdown', 'value'),\n",
    "    State('num-samples', 'value'),\n",
    "    State('model-meta-store', 'data')\n",
    ")\n",
    "# def run_prediction(n_clicks, mode, level, num_samples, model_meta):\n",
    "#     if n_clicks > 0 and level:\n",
    "#         try:\n",
    "#             if mode == 'pretrain':\n",
    "#                 model_path = os.path.join(os.pardir, \"models\", f\"best_model_{level}.pth\")\n",
    "#                 _, _, test_loader, num_classes, class_names = get_loaders(img_size=224, batch_size=16, annot=level)\n",
    "#             else:\n",
    "#                 num_classes = model_meta.get('num_classes')\n",
    "#                 class_names = model_meta.get('class_names')\n",
    "#                 if num_classes is None:\n",
    "#                     raise ValueError(\"Model metadata missing. Please run training first.\")\n",
    "#                 model_path = os.path.join(os.pardir, \"models\", \"best_model_dash.pth\")\n",
    "#             model = models.CAPResNet(num_classes, drop=0.3563).to(device)\n",
    "#             model.load_state_dict(torch.load(model_path))\n",
    "#             model.eval()\n",
    "#             test_dataset = get_datasets(224, 16, level)[2]\n",
    "#             buf = io.BytesIO()\n",
    "#             aircraft_utils.visualize_predictions(model, test_dataset, num_samples=num_samples)\n",
    "#             plt.savefig(buf, format='png')\n",
    "#             plt.close()\n",
    "#             buf.seek(0)\n",
    "#             encoded = base64.b64encode(buf.read()).decode('utf-8')\n",
    "#             img_src = f'data:image/png;base64,{encoded}'\n",
    "#             return html.Img(src=img_src, style={'width': '100%', 'marginTop': '20px'})\n",
    "#         except Exception as e:\n",
    "#             return html.Div(f\"Error running prediction: {str(e)}\", style={'color': 'red'})\n",
    "#     return \"\"\n",
    "\n",
    "\n",
    "def run_prediction(n_clicks, mode, level, num_samples, model_meta):\n",
    "    if n_clicks > 0 and level:\n",
    "        try:\n",
    "            if mode == 'pretrain':\n",
    "                model_path = os.path.join(os.pardir, \"models\", f\"best_model_{level}.pth\")\n",
    "                _, _, test_loader, num_classes, class_names = get_loaders(img_size=224, batch_size=16, annot=level)\n",
    "            else:\n",
    "                if not model_meta or 'num_classes' not in model_meta or 'class_names' not in model_meta:\n",
    "                    raise ValueError(\"Model metadata missing. Please run training or select a pre-trained model.\")\n",
    "                num_classes = model_meta['num_classes']\n",
    "                class_names = model_meta['class_names']\n",
    "                model_path = os.path.join(os.pardir, \"models\", \"best_model_dash.pth\")\n",
    "\n",
    "            model = models.CAPResNet(num_classes, drop=0.3563).to(device)\n",
    "            model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "            model.eval()\n",
    "\n",
    "            test_dataset = get_datasets(224, 16, level)[2]\n",
    "            #buf = io.BytesIO()\n",
    "            #img_src=aircraft_utils.visualize_predictions(model, test_dataset, num_samples=num_samples)\n",
    "            fig=aircraft_utils.visualize_predictions(model, test_dataset, num_samples=num_samples)\n",
    "            # plt.savefig(buf, format='png')\n",
    "            # plt.close()\n",
    "            # buf.seek(0)\n",
    "            # encoded = base64.b64encode(buf.read()).decode('utf-8')\n",
    "            # img_src = f'data:image/png;base64,{encoded}'\n",
    "            #return html.Img(src=img_src, style={'width': '100%', 'marginTop': '20px'})\n",
    "            return dcc.Graph(figure=fig, style={'width': '100%', 'marginTop': '20px'})\n",
    "        except Exception as e:\n",
    "            return html.Div(f\"Error running prediction: {str(e)}\", style={'color': 'red'})\n",
    "    return \"\"\n",
    "\n",
    "@app.callback(\n",
    "    Output('load-status', 'children'),\n",
    "    Output('level-dropdown', 'value'),\n",
    "    Input('load-button', 'n_clicks'),\n",
    "    State('path-input', 'value')\n",
    ")\n",
    "def load_dataset(n_clicks, path):\n",
    "    if n_clicks > 0 and path:\n",
    "        try:\n",
    "            for level in LEVELS:\n",
    "                loaded_datasets[level] = FGVCAircraftDataset(root=path, split='train', level=level, return_class=True)\n",
    "            return f\"Dataset loaded successfully from: {path}\", 'manufacturer'\n",
    "        except Exception as e:\n",
    "            return f\"Error loading dataset: {str(e)}\", None\n",
    "    return \"\", None\n",
    "@app.callback(\n",
    "    Output('class-dropdown', 'options'),\n",
    "    Output('class-dropdown', 'value'),\n",
    "    Input('level-dropdown', 'value')\n",
    ")\n",
    "def update_class_dropdown(level):\n",
    "    if level and level in loaded_datasets:\n",
    "        dataset = loaded_datasets[level]\n",
    "        options = [{'label': cls, 'value': cls} for cls in dataset.classes]\n",
    "        return options, options[0]['value'] if options else None\n",
    "    return [], None\n",
    "@app.callback(\n",
    "    Output('image-output', 'children'),\n",
    "    Input('level-dropdown', 'value'),\n",
    "    Input('class-dropdown', 'value')\n",
    ")\n",
    "def display_images(level, selected_class):\n",
    "    if level in loaded_datasets and selected_class:\n",
    "        dataset = loaded_datasets[level]\n",
    "        indices = [i for i, (_, cls) in enumerate(dataset.samples) if cls == selected_class]\n",
    "        if not indices:\n",
    "            return [html.Div(\"No images found for this class.\", style={'color': 'red'})]\n",
    "\n",
    "        selected_indices = random.sample(indices, min(5, len(indices)))\n",
    "        images = []\n",
    "\n",
    "        for idx in selected_indices:\n",
    "            img, cls = dataset[idx]\n",
    "            if isinstance(img, Image.Image):\n",
    "                buffer = np.array(img)\n",
    "            else:\n",
    "                buffer = img.permute(1, 2, 0).numpy()\n",
    "                buffer = (buffer * 255).astype(np.uint8)  # Convert to uint8 for display\n",
    "\n",
    "            fig = px.imshow(buffer)\n",
    "            fig.update_layout(coloraxis_showscale=False, margin=dict(l=0, r=0, t=0, b=0))\n",
    "            images.append(html.Div(dcc.Graph(figure=fig), style={'margin': '10px'}))\n",
    "\n",
    "        return images\n",
    "    return []\n",
    "\n",
    "def find_free_port():\n",
    "    s = socket.socket()\n",
    "    s.bind(('', 0))\n",
    "    return s.getsockname()[1]\n",
    "\n",
    "port = find_free_port()   \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, port=port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0384c925-e3e5-4eb3-818d-d3cb2b9bf6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/chocp/Capstone/FGVCAircraft/fgvc-aircraft-2013b/data')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd46132-768a-4225-958b-3a00a3d8cad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_predictions_plotly(model, dataset, num_samples=5):\n",
    "    model.eval()\n",
    "    fig = sub.make_subplots(rows=1, cols=num_samples)\n",
    "    for i in range(num_samples):\n",
    "        img, label = dataset[i]\n",
    "        with torch.no_grad():\n",
    "            output = model(img.unsqueeze(0).to(device))\n",
    "            probs = torch.nn.functional.softmax(output, dim=1)\n",
    "            pred = torch.argmax(probs, dim=1).item()\n",
    "            confidence = probs[0][pred].item()\n",
    "        img_np = img.permute(1, 2, 0).cpu().numpy()\n",
    "        fig.add_trace(\n",
    "            go.Image(z=img_np),\n",
    "            row=1, col=i+1\n",
    "        )\n",
    "        fig.update_xaxes(showticklabels=False, row=1, col=i+1)\n",
    "        fig.update_yaxes(showticklabels=False, row=1, col=i+1)\n",
    "        fig.layout.annotations[i].text = f\"{class_names[pred]}<br>({confidence:.2%})\"\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a386dfd1-1b33-4d37-8acf-fd4abeaef214",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_prediction(n_clicks, mode, level, num_samples, image_format, model_meta):\n",
    "    if n_clicks > 0 and level:\n",
    "        try:\n",
    "            if mode == 'pretrain':\n",
    "                model_path = os.path.join(os.pardir, \"models\", f\"best_model_{level}.pth\")\n",
    "                _, _, test_loader, num_classes, class_names = get_loaders(img_size=224, batch_size=16, annot=level)\n",
    "            else:\n",
    "                if not model_meta or 'num_classes' not in model_meta or 'class_names' not in model_meta:\n",
    "                    raise ValueError(\"Model metadata missing. Please run training or select a pre-trained model.\")\n",
    "                num_classes = model_meta['num_classes']\n",
    "                class_names = model_meta['class_names']\n",
    "                model_path = os.path.join(os.pardir, \"models\", \"best_model_dash.pth\")\n",
    "\n",
    "            model = models.CAPResNet(num_classes, drop=0.3563).to(device)\n",
    "            model.load_state_dict(torch.load(model_path))\n",
    "            model.eval()\n",
    "\n",
    "            test_dataset = get_datasets(224, 16, level)[2]\n",
    "            fig = aircraft_utils.visualize_predictions_plotly(model, test_dataset, class_names, num_samples)\n",
    "            return dcc.Graph(figure=fig)\n",
    "        except Exception as e:\n",
    "            return html.Div(f\"Error running prediction: {str(e)}\", style={'color': 'red'})\n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c6f8a7-f30e-47f6-b56b-2d08b7d61a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "html.Label(\"Select Prediction Level:\"),\n",
    "dcc.Dropdown(\n",
    "    id='predict-level-dropdown',\n",
    "    options=[{'label': lvl.title(), 'value': lvl} for lvl in LEVELS],\n",
    "    value='manufacturer'\n",
    "),\n",
    "html.Label(\"Select Image Format:\"),\n",
    "dcc.Dropdown(\n",
    "    id='image-format-dropdown',\n",
    "    options=[\n",
    "        {'label': 'PNG', 'value': 'png'},\n",
    "        {'label': 'JPEG', 'value': 'jpeg'}\n",
    "    ],\n",
    "    value='png'\n",
    "),\n",
    "html.Button('Run Prediction', id='predict-button', n_clicks=0),\n",
    "dcc.Loading(\n",
    "    id='loading-predict',\n",
    "    type='circle',\n",
    "    children=html.Div(id='prediction-output')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8190548-1abc-455e-8212-1bac09ae28cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@app.callback(\n",
    "    Output('prediction-output', 'children'),\n",
    "    Input('predict-button', 'n_clicks'),\n",
    "    State('mode-selector', 'value'),\n",
    "    State('predict-level-dropdown', 'value'),\n",
    "    State('num-samples', 'value'),\n",
    "    State('image-format-dropdown', 'value'),\n",
    "    State('model-meta-store', 'data')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34064964-f80e-4f2c-93a5-f7796b9bd71f",
   "metadata": {},
   "source": [
    "Add a README or Usage Instructions\n",
    "Include a section in your README like:\n",
    "# Clone the repo\n",
    "\n",
    "git clone https://github.com/mabbts/CV_aircraft_classifier_capstone_project.git\n",
    "\n",
    "cd CV_aircraft_classifier_capstone_project\n",
    "\n",
    "# Run the script\n",
    "\n",
    "\n",
    "python main.py\n",
    "\n",
    "You can also include a requirements.txt or setup.py to help users install dependencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bd332f-18b5-4525-8748-069018142d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e960b796-e52c-41e0-bbf4-eea4bce7c55f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
